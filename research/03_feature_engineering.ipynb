{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anonymous/PycharmProjects/MLOps_heart_disease'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class FeatureEngineeringConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    target_column: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlhrtds.constants import *\n",
    "from mlhrtds.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_transformation_config(self) -> FeatureEngineeringConfig:\n",
    "        config = self.config.data_transformation\n",
    "        schema =  self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = FeatureEngineeringConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            target_column = schema.name\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlhrtds import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlhrtds import logger\n",
    "from mlhrtds.utils.common import read_yaml, create_directories\n",
    "\n",
    "# Assuming FeatureEngineeringConfig is defined elsewhere\n",
    "# from mlds.entity.config_entity import FeatureEngineeringConfig\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: FeatureEngineeringConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train_test_splitting(self):\n",
    "        # Read the data from the specified path\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        \n",
    "\n",
    "        # Split the data into X (features) and y (target)\n",
    "        X = data.drop([self.config.target_column], axis=1)\n",
    "        y = data[[self.config.target_column]]\n",
    "        \n",
    "        # Define categorical and numerical columns\n",
    "        categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "        numerical_columns = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "        # Perform one-hot encoding for categorical columns\n",
    "        X = pd.get_dummies(X, columns=categorical_columns)\n",
    "        print(X)\n",
    "        # Define categorical and numerical columns\n",
    "        categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "        numerical_columns = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "        # Split the data into training and test sets (75% train, 25% test)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "        # X_train.shape\n",
    "        # X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "        # Define transformers for numerical features (scaling in this case) .reshape(-1, 1)\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        # Define transformers for categorical features (one-hot encoding)\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder())  # You can customize options for encoding here\n",
    "        ])\n",
    "\n",
    "        # Combine transformers using ColumnTransformer\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, numerical_columns),\n",
    "                ('cat', categorical_transformer, categorical_columns)\n",
    "            ])\n",
    "\n",
    "        # Create the final data preprocessing pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "        # Fit and transform the training data\n",
    "        X_train_transformed = pipeline.fit_transform(X_train.shape)\n",
    "\n",
    "        # Transform the test data\n",
    "        X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "        # Save the transformed data\n",
    "        pd.DataFrame(X_train_transformed).to_csv(os.path.join(self.config.root_dir, \"X_train.csv\"), index=False)\n",
    "        pd.DataFrame(y).to_csv(os.path.join(self.config.root_dir, \"y_train.csv\"), index=False)\n",
    "        pd.DataFrame(X_test_transformed).to_csv(os.path.join(self.config.root_dir, \"X_test.csv\"), index=False)\n",
    "        pd.DataFrame(y_test).to_csv(os.path.join(self.config.root_dir, \"y_test.csv\"), index=False)\n",
    "        print(\"Splitted data into training and test sets and performed feature engineering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-20 21:04:12,358: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-09-20 21:04:12,361: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-09-20 21:04:12,364: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-09-20 21:04:12,366: INFO: common: created directory at: artifacts]\n",
      "[2023-09-20 21:04:12,368: INFO: common: created directory at: artifacts/data_transformation]\n",
      "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
      "0      19  27.900         0        True     False      False        True   \n",
      "1      18  33.770         1       False      True       True       False   \n",
      "2      28  33.000         3       False      True       True       False   \n",
      "3      33  22.705         0       False      True       True       False   \n",
      "4      32  28.880         0       False      True       True       False   \n",
      "...   ...     ...       ...         ...       ...        ...         ...   \n",
      "1333   50  30.970         3       False      True       True       False   \n",
      "1334   18  31.920         0        True     False       True       False   \n",
      "1335   18  36.850         0        True     False       True       False   \n",
      "1336   21  25.800         0        True     False       True       False   \n",
      "1337   61  29.070         0        True     False      False        True   \n",
      "\n",
      "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
      "0                False             False             False              True  \n",
      "1                False             False              True             False  \n",
      "2                False             False              True             False  \n",
      "3                False              True             False             False  \n",
      "4                False              True             False             False  \n",
      "...                ...               ...               ...               ...  \n",
      "1333             False              True             False             False  \n",
      "1334              True             False             False             False  \n",
      "1335             False             False              True             False  \n",
      "1336             False             False             False              True  \n",
      "1337             False              True             False             False  \n",
      "\n",
      "[1338 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1003 11].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     data_transform\u001b[39m.\u001b[39mtrain_test_splitting()\n\u001b[1;32m      6\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     data_transformation_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_data_transformation_config()\n\u001b[1;32m      4\u001b[0m     data_transform \u001b[39m=\u001b[39m DataTransformation(config\u001b[39m=\u001b[39mdata_transformation_config)\n\u001b[0;32m----> 5\u001b[0m     data_transform\u001b[39m.\u001b[39;49mtrain_test_splitting()\n\u001b[1;32m      6\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m      7\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m, in \u001b[0;36mDataTransformation.train_test_splitting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor)])\n\u001b[1;32m     62\u001b[0m \u001b[39m# Fit and transform the training data\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m X_train_transformed \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit_transform(X_train\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     65\u001b[0m \u001b[39m# Transform the test data\u001b[39;00m\n\u001b[1;32m     66\u001b[0m X_test_transformed \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mtransform(X_test)\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/pipeline.py:472\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    470\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m    471\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 472\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    473\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:736\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit all transformers, transform the data and concatenate results.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \n\u001b[1;32m    716\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39m    sparse matrices.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 736\u001b[0m X \u001b[39m=\u001b[39m _check_X(X)\n\u001b[1;32m    737\u001b[0m \u001b[39m# set n_features_in_ attribute\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:921\u001b[0m, in \u001b[0;36m_check_X\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m    920\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m check_array(X, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m)\n",
      "File \u001b[0;32m~/PycharmProjects/MLOps_heart_disease/sommy/lib/python3.9/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1003 11].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config =  ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transform = DataTransformation(config=data_transformation_config)\n",
    "    data_transform.train_test_splitting()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.087167</td>\n",
       "      <td>-1.140875</td>\n",
       "      <td>-0.917500</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>1.754205</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>-0.571594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.802106</td>\n",
       "      <td>-0.665842</td>\n",
       "      <td>0.743605</td>\n",
       "      <td>1.009014</td>\n",
       "      <td>-1.009014</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>1.694871</td>\n",
       "      <td>-0.571594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.836992</td>\n",
       "      <td>1.528794</td>\n",
       "      <td>-0.086947</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>1.749494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551932</td>\n",
       "      <td>0.926476</td>\n",
       "      <td>-0.086947</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>-1.966960</td>\n",
       "      <td>1.966960</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>1.694871</td>\n",
       "      <td>-0.571594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.480667</td>\n",
       "      <td>-0.268178</td>\n",
       "      <td>0.743605</td>\n",
       "      <td>1.009014</td>\n",
       "      <td>-1.009014</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>1.749494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.514757</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>2.404710</td>\n",
       "      <td>1.009014</td>\n",
       "      <td>-1.009014</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>1.730900</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>-0.571594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.018189</td>\n",
       "      <td>-1.105101</td>\n",
       "      <td>3.235263</td>\n",
       "      <td>1.009014</td>\n",
       "      <td>-1.009014</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>1.694871</td>\n",
       "      <td>-0.571594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.335848</td>\n",
       "      <td>-0.887967</td>\n",
       "      <td>-0.917500</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>1.730900</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>-0.571594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>-0.160720</td>\n",
       "      <td>2.843247</td>\n",
       "      <td>0.743605</td>\n",
       "      <td>1.009014</td>\n",
       "      <td>-1.009014</td>\n",
       "      <td>-1.966960</td>\n",
       "      <td>1.966960</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>1.749494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.122053</td>\n",
       "      <td>-0.101792</td>\n",
       "      <td>-0.917500</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>-0.508399</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>-0.590015</td>\n",
       "      <td>1.749494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -1.087167 -1.140875 -0.917500 -0.991067  0.991067  0.508399 -0.508399   \n",
       "1    -0.802106 -0.665842  0.743605  1.009014 -1.009014  0.508399 -0.508399   \n",
       "2     0.836992  1.528794 -0.086947 -0.991067  0.991067  0.508399 -0.508399   \n",
       "3     0.551932  0.926476 -0.086947 -0.991067  0.991067 -1.966960  1.966960   \n",
       "4     0.480667 -0.268178  0.743605  1.009014 -1.009014  0.508399 -0.508399   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "998  -1.514757  0.139468  2.404710  1.009014 -1.009014  0.508399 -0.508399   \n",
       "999  -0.018189 -1.105101  3.235263  1.009014 -1.009014  0.508399 -0.508399   \n",
       "1000  1.335848 -0.887967 -0.917500 -0.991067  0.991067  0.508399 -0.508399   \n",
       "1001 -0.160720  2.843247  0.743605  1.009014 -1.009014 -1.966960  1.966960   \n",
       "1002  1.122053 -0.101792 -0.917500 -0.991067  0.991067  0.508399 -0.508399   \n",
       "\n",
       "             7         8         9        10  \n",
       "0    -0.577734  1.754205 -0.590015 -0.571594  \n",
       "1    -0.577734 -0.570059  1.694871 -0.571594  \n",
       "2    -0.577734 -0.570059 -0.590015  1.749494  \n",
       "3    -0.577734 -0.570059  1.694871 -0.571594  \n",
       "4    -0.577734 -0.570059 -0.590015  1.749494  \n",
       "...        ...       ...       ...       ...  \n",
       "998   1.730900 -0.570059 -0.590015 -0.571594  \n",
       "999  -0.577734 -0.570059  1.694871 -0.571594  \n",
       "1000  1.730900 -0.570059 -0.590015 -0.571594  \n",
       "1001 -0.577734 -0.570059 -0.590015  1.749494  \n",
       "1002 -0.577734 -0.570059 -0.590015  1.749494  \n",
       "\n",
       "[1003 rows x 11 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/home/anonymous/PycharmProjects/MLOps_heart_disease/artifacts/data_transformation/X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sommy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
